参考资料：
    https://www.cnblogs.com/zhuifeng523/p/11641792.html
    https://blog.csdn.net/qq_41699100/article/details/86102235

1、传统数据库遵循 ACID 规则,NoSql一般遵循 CAP 定理
    ACID:
        A(Atomicity):原子性、C(Consistency):一致性、I(Isolation):隔离性、D(Durability):持久性
    CAP:
        C(Consistency)一致性:
            指在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）
        A(Availability)可用性:
            在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据更新具备高可用性）
        P(Partition tolerance)分区容忍性:
            即当节点之间无法正常通信时，就产生了分区，而分区产生后，依然能够保证服务可用，那么我们就说系统是分区容忍的。
            显然如果节点越多，且备份越多，分区容忍度就越高（因为即便是其中一个或多个节点挂了，仍然有其它节点和备份可用）。
    为什么说CAP三个特性无法全部保证呢？
    首先，假如我们要保证分区容忍性，必然要做多个副本节点，而这必然会带来一致性的问题，即保证多个节点的数据是相同的，
    但是，要让多个节点数据相同，就必须要花时间去复制数据，这还是能够正常通信的情况下，那么在数据复制的过程中为了保持
    一致性，就不能对外提供服务，所以这段时间就无法满足可用性的问题

2、Redis分布式锁
    2.1、普通实现
    2.2、Redlock实现
2、Redis为什么是单进程单线程:
    Redis是单进程单线程的，Redis利用队列技术将并发访问变为串行访问，消除了传统数据库串行控制的开销
   Redis为什么是单线程
    多线程处理会涉及到锁，而且多线程处理会涉及到线程切换而消耗CPU。因为CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存
    或者网络带宽。单线程无法发挥多核CPU性能，不过可以通过在单机开多个Redis实例来解决

    官方FAQ表示，因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线
    程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦！）Redis利用队列技术将
    并发访问变为串行访问
    1）绝大部分请求是纯粹的内存操作（非常快速）2）采用单线程,避免了不必要的上下文切换和竞争条件
    3）非阻塞IO优点：
    1.速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)
    2. 支持丰富数据类型，支持string，list，set，sorted set，hash
    3.支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行
    4. 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除如何解决redis的并发竞争key问题

    同时有多个子系统去set一个key。这个时候要注意什么呢？ 不推荐使用redis的事务机制。因为我们的生产环境，基本都是redis集群
    环境，做了数据分片操作。你一个事务中有涉及到多个key操作的时候，这多个key不一定都存储在同一个redis-server上。因此，
    redis的事务机制，十分鸡肋。
    (1)如果对这个key操作，不要求顺序： 准备一个分布式锁，大家去抢锁，抢到锁就做set操作即可
    (2)如果对这个key操作，要求顺序： 分布式锁+时间戳。 假设这会系统B先抢到锁，将key1设置为{valueB 3:05}。接下来系统A抢到锁，
    发现自己的valueA的时间戳早于缓存中的时间戳，那就不做set操作了。以此类推。
    (3) 利用队列，将set方法变成串行访问也可以redis遇到高并发，如果保证读写key的一致性
    对redis的操作都是具有原子性的,是线程安全的操作,你不用考虑并发问题,redis内部已经帮你处理好并发的问题了

    为什么Redis的操作是原子性的，怎么保证原子性的？
    对于Redis而言，命令的原子性指的是：一个操作的不可以再分，操作要么执行，要么不执行。
    Redis的操作之所以是原子性的，是因为Redis是单线程的。
    Redis本身提供的所有API都是原子操作，Redis中的事务其实是要保证批量操作的原子性。
    多个命令在并发中也是原子性的吗？
    不一定， 将get和set改成单命令操作，incr 。使用Redis的事务，或者使用Redis+Lua==的方式实现.

    Redis事务
    Redis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的
    Redis会将一个事务中的所有命令序列化，然后按顺序执行。
    1.redis 不支持回滚“Redis 在事务失败时不进行回滚，而是继续执行余下的命令”， 所以 Redis 的内部可以保持简单且快速。
    2.如果在一个事务中的命令出现错误，那么所有的命令都不会执行；
    3.如果在一个事务中出现运行错误，那么正确的命令会被执行。

    1）MULTI命令用于开启一个事务，它总是返回OK。 MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即
    被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行。
    2）EXEC：执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。 当操作被打断时，返回空值 nil 。
    3）通过调用DISCARD，客户端可以清空事务队列，并放弃执行事务， 并且客户端会从事务状态中退出。
    4）WATCH 命令可以为 Redis 事务提供 check-and-set （CAS）行为。 可以监控一个或多个键，一旦其中有一个键被修改（或删除），
    之后的事务就不会执行，监控一直持续到EXEC命令。

   单线程的redis为什么这么快
    纯内存操作
    单线程操作，避免了频繁的上下文切换
    采用了非阻塞I/O多路复用机制
   延伸：
     Nginx：多进程单线程模型
     Memcached：单进程多线程模型

3、Redis优势：
    1.速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)
    2. 支持丰富数据类型，支持string，list，set，sorted set，hash
    3.支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行
    4. 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除

4、Redis单点吞吐量
    单点TPS达到8万/秒，QPS达到10万/秒，补充下TPS和QPS的概念
    1.QPS: 应用系统每秒钟最大能接受的用户访问量
    每秒钟处理完请求的次数，注意这里是处理完，具体是指发出请求到服务器处理完成功返回结果。可以理解在server中有个counter，
    每处理一个请求加1，1秒后counter=QPS。
    2.TPS： 每秒钟最大能处理的请求数
    每秒钟处理完的事务次数，一个应用系统1s能完成多少事务处理，一个事务在分布式处理中，可能会对应多个请求，对于衡量单个
    接口服务的处理能力，用QPS比较合理。

5、Redis相比memcached有哪些优势？
    1.memcached所有的值均是简单的字符串，Redis作为其替代者，支持更为丰富的数据类型
    2.Redis的速度比memcached快很多
    3.Redis可以持久化其数据
    4.Redis支持数据的备份，即master-slave模式的数据备份。

   Memcache与Redis的区别都有哪些？
    1)、存储方式 Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。 Redis有部份存在硬盘上，redis可以
    持久化其数据
    2)、数据支持类型 memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型 ，提供list，set，zset，
    hash等数据结构的存储
    3)、使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。 Redis直接自己构建了VM 机制 ，因为
    一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。
    4). value 值大小不同：Redis 最大可以达到 1gb；memcache 只有 1mb。
    5）redis的速度比memcached快很多
    6）Redis支持数据的备份，即master-slave模式的数据备份。

6、Redis过期策略以及内存淘汰机制：
    在Redis中，允许用户设置最大使用内存大小server.maxmemory，当Redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。
    1.volatile-lru:从已设置过期的数据集中挑选最近最少使用的淘汰
    2.volatile-ttr:从已设置过期的数据集中挑选将要过期的数据淘汰
    3.volatile-random:从已设置过期的数据集中任意挑选数据淘汰
    4.allkeys-lru:从数据集中挑选最近最少使用的数据淘汰
    5.allkeys-random:从数据集中任意挑选数据淘汰
    6.noenviction:禁止淘汰数据
    redis淘汰数据时还会同步到aof

    redis采用的是定期删除+惰性删除策略。
    为什么不用定时删除策略?
    定时删除,用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间
    应用在处理请求，而不是删除key,因此没有采用这一策略.
    定期删除+惰性删除是如何工作的呢?
    定期删除，redis默认每个100ms检查，是否有过期的key,有过期key则删除。需要说明的是，redis不是每个100ms将所有的key检查一次，
    而是随机抽取进行检查(如果每隔100ms,全部key进行检查，redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到
    时间没有删除。
    于是，惰性删除派上用场。也就是说在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果
    过期了此时就会删除。
    采用定期删除+惰性删除就没其他问题了么?
    不是的，如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。那么
    就应该采用内存淘汰机制。
    在redis.conf中有一行配置：maxmemory-policy volatile-lru
    该配置就是配内存淘汰策略的(什么，你没配过？好好反省一下自己)
    volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
    volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
    volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
    allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰
    allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
    no-enviction（驱逐）：禁止驱逐数据，新写入操作会报错
    ps：如果没有设置 expire 的key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略
    的行为, 和 noeviction(不删除) 基本上一致。


7、持久化机制：RDB和AOF；
    1.RDB
     默认开启，会按照配置的指定时间将内存中的数据快照到磁盘中，创建一个dump.rdb文件，Redis启动时再恢复到内存中。
     Redis会单独创建fork()一个子进程，将当前父进程的数据库数据复制到子进程的内存中，然后由子进程写入到临时文件中，
     持久化的过程结束了，再用这个临时文件替换上次的快照文件，然后子进程退出，内存释放。
     需要注意的是，每次快照持久化都会将主进程的数据库数据复制一遍，导致内存开销加倍，若此时内存不足，则会阻塞服务器运行，
     直到复制结束释放内存；都会将内存数据完整写入磁盘一次，所以如果数据量大的话，而且写操作频繁，必然会引起大量的磁盘I/O操作，
     严重影响性能，并且最后一次持久化后的数据可能会丢失；
    3.AOF
    以日志的形式记录每个写操作（读操作不记录），只需追加文件但不可以改写文件，Redis启动时会根据日志从头到尾全部执行一遍
    以完成数据的恢复工作。包括flushDB也会执行。
    主要有两种方式触发：有写操作就写、每秒定时写（也会丢数据）。
    因为AOF采用追加的方式，所以文件会越来越大，针对这个问题，新增了重写机制，就是当日志文件大到一定程度的时候，会fork出
    一条新进程来遍历进程内存中的数据，每条记录对应一条set语句，写到临时文件中，然后再替换到旧的日志文件（类似rdb的操作方式）。
    默认触发是当aof文件大小是上次重写后大小的一倍且文件大于64M时触发。
    当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。一般情况下，只要使用默认开启的RDB即可，因为相对于AOF，RDB便于
    进行数据库备份，并且恢复数据集的速度也要快很多。
    开启持久化缓存机制，对性能会有一定的影响，特别是当设置的内存满了的时候，更是下降到几百reqs/s。所以如果只是用来做缓存
    的话，可以关掉持久化。

8、Redis常见性能问题和解决方案：
  (1) Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件
  (2) 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次
  (3) 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内
  (4) 尽量避免在压力很大的主库上增加从库
  (5) 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master <- Slave1 <- Slave2 <- Slave3…
  这样的结构方便解决单点故障问题，实现Slave对Master的替换。如果Master挂了，可以立刻启用Slave1做Master，其他不变

9、缓存雪崩、缓存穿透、缓存预热、缓存更新、缓存降级等问题
    缓存雪崩我们可以简单的理解为：由于原有缓存失效，新缓存未到期间，全部请求都跑去数据库
    (例如：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期)，所有原本应该访问缓存的请求都去查询数据库了，
    而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃。
    解决办法：
    大多数系统设计者考虑用加锁（ 最多的解决方案）或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免
    失效时大量的并发请求落到底层存储系统上。还有一个简单方案就时讲缓存失效时间分散开。
    事发前：实现Redis的高可用(主从架构+Sentinel 或者Redis Cluster)，尽量避免Redis挂掉这种情况发生。
    事发中：万一Redis真的挂了，我们可以设置本地缓存(ehcache)+限流(hystrix)，尽量避免我们的数据库被干掉(起码能保证我们的
    服务还是能正常工作的)
    事发后：redis持久化，重启后自动从磁盘上加载数据，快速恢复缓存数据


    二、缓存穿透
    缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去
    数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。这样请求就绕过缓存直接查数据库，这也是经常提的缓存命中率
    问题。缓存穿透如果发生了，也可能把我们的数据库搞垮，导致整个服务瘫痪！
    解决办法;
    最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，
    从而避免了对底层存储系统的查询压力。
    另外也有一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进
    行缓存，但它的过期时间会很短，最长不超过五分钟。通过这个直接设置的默认值存放到缓存，这样第二次到缓冲中获取就有值了，
    而不会继续访问数据库，这种办法最简单粗暴。
    5TB的硬盘上放满了数据，请写一个算法将这些数据进行排重。如果这些数据是一些32bit大小的数据该如何解决？如果是64bit的呢？

    对于空间的利用到达了一种极致，那就是Bitmap和布隆过滤器(Bloom Filter)。
    Bitmap： 典型的就是哈希表
    缺点是，Bitmap对于每个元素只能记录1bit信息，如果还想完成额外的功能，恐怕只能靠牺牲更多的空间、时间来完成了。

    布隆过滤器（推荐）
    就是引入了k(k>1)k(k>1)个相互独立的哈希函数，保证在给定的空间、误判率下，完成元素判重的过程。
    它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。
    Bloom-Filter算法的核心思想就是利用多个不同的Hash函数来解决“冲突”。
    Hash存在一个冲突（碰撞）的问题，用同一个Hash得到的两个URL的值有可能相同。为了减少冲突，我们可以多引入几个Hash，如果
    通过其中的一个Hash值我们得出某元素不在集合中，那么该元素肯定不在集合中。只有在所有的Hash函数告诉我们该元素在集合中时，
    才能确定该元素存在于集合中。这便是Bloom-Filter的基本思想。
    Bloom-Filter一般用于在大数据量的集合中判定某元素是否存在。

    三、缓存预热
    缓存预热这个应该是一个比较常见的概念，相信很多小伙伴都应该可以很容易的理解，缓存预热就是系统上线后，将相关的缓存数据
    直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！
    解决思路：
    1、直接写个缓存刷新页面，上线时手工操作下；
    2、数据量不大，可以在项目启动的时候自动进行加载；
    3、定时刷新缓存；

    四、缓存更新
    除了缓存服务器自带的缓存失效策略之外（Redis默认的有6中策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰，
    常见的策略有两种：
    （1）定时去清理过期的缓存；
    （2）当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。
    两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对
    比较复杂！具体用哪种方案，大家可以根据自己的应用场景来权衡。
    五、缓存降级
    当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，
    即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。
    降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。
    以参考日志级别设置预案：
    （1）一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；
    （2）警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；
    （3）错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况
    自动降级或者人工降级；
    （4）严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。

    服务降级的目的，是为了防止Redis服务故障，导致数据库跟着一起发生雪崩问题。因此，对于不重要的缓存数据，可以采取服务
    降级策略，例如一个比较常见的做法就是，Redis出现问题，不去数据库查询，而是直接返回默认值给用户。

10、热点数据和冷数据是什么
    热点数据，缓存才有价值
    对于冷数据而言，大部分数据可能还没有再次访问到就已经被挤出内存，不仅占用内存，而且价值不大。频繁修改的数据，看情况
    考虑使用缓存
    对于上面两个例子，寿星列表、导航信息都存在一个特点，就是信息修改频率不高，读取通常非常高的场景。
    对于热点数据，比如我们的某IM产品，生日祝福模块，当天的寿星列表，缓存以后可能读取数十万次。再举个例子，某导航产品，
    我们将导航信息，缓存以后可能读取数百万次。
    **数据更新前至少读取两次，**缓存才有意义。这个是最基本的策略，如果缓存还没有起作用就失效了，那就没有太大价值了。
    那存不存在，修改频率很高，但是又不得不考虑缓存的场景呢？有！比如，这个读取接口对数据库的压力很大，但是又是热点数据，
    这个时候就需要考虑通过缓存手段，减少数据库的压力，比如我们的某助手产品的，点赞数，收藏数，分享数等是非常典型的热点
    数据，但是又不断变化，此时就需要将数据同步保存到Redis缓存，减少数据库压力。

11、Redis的五种数据类型，以及每种数据类型的使用场景
   (一)String
   这个其实没啥好说的，最常规的set/get操作，value可以是String也可以是数字。一般做一些复杂的计数功能的缓存。
   (二)hash
   这里value存放的是结构化的对象，比较方便的就是操作其中的某个字段。博主在做单点登录的时候，就是用这种数据结构存储用户
   信息，以cookieId作为key，设置30分钟为缓存过期时间，能很好的模拟出类似session的效果。
   (三)list
   使用List的数据结构，可以做简单的消息队列的功能。另外还有一个就是，可以利用lrange命令，做基于redis的分页功能，性能极佳，
   用户体验好。本人还用一个场景，很合适—取行情信息。就也是个生产者和消费者的场景。LIST可以很好的完成排队，先进先出的原则。
   (四)set
   因为set堆放的是一堆不重复值的集合。所以可以做全局去重的功能。为什么不用JVM自带的Set进行去重？因为我们的系统一般都是
   集群部署，使用JVM自带的Set，比较麻烦，难道为了一个做一个全局去重，再起一个公共服务，太麻烦了。
   另外，就是利用交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。
   (五)sorted set
   sorted set多了一个权重参数score,集合中的元素能够按score进行排列。可以做排行榜应用，取TOP N操作
11、汇总：
    Redis支持的Java客户端都有哪些？官方推荐用哪个？
    Redisson、Jedis、lettuce等等，官方推荐使用Redisson。

    Jedis与Redisson对比有什么优缺点？
    Jedis是Redis的Java实现的客户端，其API提供了比较全面的Redis命令的支持；Redisson实现了分布式和可扩展的Java数据结构，
    和Jedis相比，功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等Redis特性。Redisson的宗旨是促进使用者
    对Redis的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上

    Redis哈希槽的概念：
    Redis集群没有使用一致性hash,而是引入了哈希槽的概念，当需要在 Redis 集群中放置一个 key-value 时，根据
     CRC16(key) mod 16384的值，决定将一个key放到哪个桶中。

    Redis集群最大节点个数是多少：
    Redis集群预分好16384个桶(哈希槽)

    Redis集群的主从复制模型是怎样的：
    为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型,每个节点都会有N-1个复制品.

    Redis集群会有写操作丢失吗？为什么？
    Redis并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作。

    Redis集群之间是如何复制的？
    异步复制

    Redis如何做内存优化？
    尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象
    到一个散列表里面。比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key,而是应该把这个
    用户的所有信息存储到一张散列表里面.

    Redis回收进程如何工作的？
    一个客户端运行了新的命令，添加了新的数据。
    Redi检查内存使用情况，如果大于maxmemory的限制, 则根据设定好的策略进行回收。

    Redis回收使用的是什么算法？
    LRU算法

    一个字符串类型的值能存储最大容量是多少？
    512M

    为什么要做Redis分区？
    分区可以让Redis管理更大的内存，Redis将可以使用所有机器的内存。如果没有分区，你最多只能使用一台机器的内存。分区使
    Redis的计算能力通过简单地增加计算机得到成倍提升,Redis的网络带宽也会随着计算机和网卡的增加而成倍增长

    你知道有哪些Redis分区实现方案？
    客户端分区就是在客户端就已经决定数据会被存储到哪个redis节点或者从哪个redis节点读取。大多数客户端已经实现了客户端分区。
    代理分区 意味着客户端将请求发送给代理，然后代理决定去哪个节点写数据或者读数据。代理根据分区规则决定请求哪些Redis实例，
    然后根据Redis的响应结果返回给客户端。redis和memcached的一种代理实现就是Twemproxy查询路由(Query routing) 的意思是客户
    端随机地请求任意一个redis实例，然后由Redis将请求转发给正确的Redis节点。Redis Cluster实现了一种混合形式的查询路由，
    但并不是直接将请求从一个redis节点转发到另一个redis节点，而是在客户端的帮助下直接redirected到正确的redis节点。

    Redis分区有什么缺点？
    涉及多个key的操作通常不会被支持。例如你不能对两个集合求交集，因为他们可能被存储到不同的Redis实例（实际上这种情况也
    有办法，但是不能直接使用交集指令）。同时操作多个key,则不能使用Redis事务.分区使用的粒度是key，不能使用一个非常长的
    排序key存储一个数据集（The partitioning granularity is the key, so it is not possible to shard a dataset with a
    single huge key like a very big sorted set）.当使用分区的时候，数据处理会非常复杂，例如为了备份你必须从不同的Redis
    实例和主机同时收集RDB / AOF文件。分区时动态扩容或缩容可能非常复杂。Redis集群在运行时增加或者删除Redis节点，能做到
    最大程度对用户透明地数据再平衡，但其他一些客户端分区或者代理分区方法则不支持这种特性。然而，有一种预分片的技术也可
    以较好的解决这个问题

     Redis持久化数据和缓存怎么做扩容？
     如果Redis被当做缓存使用，使用一致性哈希实现动态扩容缩容。如果Redis被当做一个持久化存储使用，必须使用固定的
     keys-to-nodes映射关系，节点的数量一旦确定不能变化。否则的话(即Redis节点需要动态变化的情况），必须使用可以在运行时
     进行数据再平衡的一套系统，而当前只有Redis集群可以做到这样

    分布式Redis是前期做还是后期规模上来了再做好？为什么？
    既然Redis是如此的轻量（单实例只使用1M内存）,为防止以后的扩容，最好的办法就是一开始就启动较多实例。即便你只有一台服务
    器，你也可以一开始就让Redis以分布式的方式运行，使用分区，在同一台服务器上启动多个实例。一开始就多设置几个Redis实例，
    例如32或者64个实例，对大多数用户来说这操作起来可能比较麻烦，但是从长久来看做这点牺牲是值得的。这样的话，当你的数据不
    断增长，需要更多的Redis服务器时，你需要做的就是仅仅将Redis实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区
    的问题）。一旦你添加了另一台服务器，你需要将你一半的Redis实例从第一台机器迁移到第二台机器

    对于大量的请求怎么样处理
    redis是一个单线程程序，也就说同一时刻它只能处理一个客户端请求；
    redis是通过IO多路复用（select，epoll, kqueue，依据不同的平台，采取不同的实现）来处理多个客户端请求的

    Redis有哪些适合的场景？
    1）Session共享(单点登录)
    2）页面缓存
    3）队列
    4）排行榜/计数器
    5）发布/订阅